# SLAM Bot
---
*Utilizing lidar to control robot via web UI with thetastar navigation*
---
## SLAM
### Simultanious localization and mapping, it finds the location of the robot relative to a map, and also discovers new parts of the map, simultaniously, as the name should suggest.
---
## Thetastar
### I didn't use the star symbol because I don't want to mess up the markdown. Thetastar is a vairiation of a star that uses line of sight (los) checks across the bitmap to see if a node is reachable. Currently, it calculates a route based off of a point given in the web browser
---
## Improvements later on:
- Using arcs for thetastar calculations
- Optimizing for time instead of distance with physics calculations
- Running neural networks on the robot for navigation
- Tracking and following objects
- Implementing 3D lidar or ToF
- More advanced navigation (Routines, avoid other moving objects.
---
## List of parts:
- 1 x Raspberry Pi Zero 2 W
- 2 x DfRobot Micro DC Motor with Encoder-SJ01
- 1 x Printed circuit board
- 1 x Raspberry Pi Header
- 1 x RpLidar A1
- 1 x 9 Volt battery
- 1 x Barrel jack adapter for battery
- 1 x Barrel jack for circuit board
- 1 x 5V regulator (1.5 A)
- 1 x 30mm Fan
